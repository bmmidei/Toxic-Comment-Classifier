{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "_uuid": "48e7d0b17674d65f7ca1d5994325e7ffe485af69"
   },
   "source": [
    "# ConvNet Training\nThis notebook can be used to train a CNN for text classification and generate predictions for the Kaggle competition found [here](https://www.kaggle.com/c/quora-insincere-questions-classification). \n\nThe notebook utilizes Keras and GloVe for preprocessing using word embeddings. Then, Keras with Tensorflow backend is used for training a deep CNN. Feel free to fork!\n\n### Acknowledgements\n* Richard Liao's [blog post](https://richliao.github.io/supervised/classification/2016/11/26/textclassifier-convolutional/) for starter code for the cnn\n* Vladimir Demidov's [notebook](https://www.kaggle.com/yekenot/2dcnn-textclassifier) for the F1 Score calculation\n* This great [blog post](http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/11/27/Understanding-Convolutions-In-Text/) for understanding convolution in text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true,
    "_uuid": "31651e5a58fc9229e683afac2cbc7b0948a5f240"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Embedding, Dropout\n",
    "from keras.layers import Conv1D, MaxPool1D, Flatten, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true,
    "_uuid": "9dc94191884a37933e64d2d822040a9779a621fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in training and testing data\n",
    "train_df = pd.read_csv('./input/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true,
    "_uuid": "78488b53255b19d912481adbc91f5bcf0410e689"
   },
   "outputs": [],
   "source": [
    "# Extract the training data and corresponding labels\n",
    "text = train_df['question_text'].fillna('unk').values\n",
    "labels = train_df['target'].values\n",
    "\n",
    "# Split into training and validation sets by making use of the scikit-learn\n",
    "# function train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(text, labels,\\\n",
    "                                                  test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true,
    "_uuid": "e00b006b3a940240da8d4d8b2bfda5765a9f7a40"
   },
   "outputs": [],
   "source": [
    "embed_size = 300 # Size of each word vector\n",
    "max_words = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true,
    "_uuid": "3d68827dba2948ee2ef7dd4be10a1fa4dd629e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word index consists of 196345 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "# The tokenizer will assign an integer value to each word in the dictionary\n",
    "# and then convert each string of words into a list of integer values\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('The word index consists of {} unique tokens.'.format(len(word_index)))\n",
    "\n",
    "## Pad the sentences to the maximum length\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true,
    "_uuid": "96e773c808de88d2054a64b34f060067dd7e65d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding dictionary has 2195884 items\n"
     ]
    }
   ],
   "source": [
    "# Create the embedding dictionary from the word embedding file\n",
    "embedding_dict = {}\n",
    "filename = os.path.join('./input/embeddings/', 'glove.840B.300d/glove.840B.300d.txt')\n",
    "with open(filename) as f:\n",
    "    for line in f:\n",
    "        line = line.split()\n",
    "        token = line[0]\n",
    "        try:\n",
    "            coefs = np.asarray(line[1:], dtype='float32')\n",
    "            embedding_dict[token] = coefs\n",
    "        except:\n",
    "            pass\n",
    "print('The embedding dictionary has {} items'.format(len(embedding_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true,
    "_uuid": "8d673151e5ccf77cfdb94aed6e2e64883e490dac"
   },
   "outputs": [],
   "source": [
    "# Create the embedding layer weight matrix\n",
    "embed_mat = np.zeros(shape=[max_words, embed_size])\n",
    "for word, idx in word_index.items():\n",
    "    # Word index is ordered from most frequent to least frequent\n",
    "    # Ignore words that occur less frequently\n",
    "    if idx >= max_words: continue\n",
    "    vector = embedding_dict.get(word)\n",
    "    if vector is not None:\n",
    "        embed_mat[idx] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true,
    "_uuid": "1e4ec3f078dc5ca43669238813d5ebcadf6ab39d"
   },
   "outputs": [],
   "source": [
    "def create_cnn(filter_sizes, strides, num_filters, embed_train=False, dropout=0.1):\n",
    "    # The first layer will be the word embedding layer\n",
    "    # by default, the embedding layer will not be trainable\n",
    "    sequence_input = Input(shape=(maxlen,), dtype='int32')\n",
    "    x = Embedding(max_words, embed_size, weights=[embed_mat], trainable=embed_train)(sequence_input)\n",
    "    \n",
    "    # Convolutional and maxpool layers for each filter size and stride size\n",
    "    # Convolution is 1D and occurs at different stride lengths.\n",
    "    # eg. a filter size of 3 and stride of 2 will examine 3 words at a time\n",
    "    # in the order 0,1,2 - 2,3,4 - 4,5,6 - etc\n",
    "    conv_layers = []\n",
    "    maxpool_layers = []\n",
    "    for i in range(len(filter_sizes)):\n",
    "        conv_layers.append(Conv1D(num_filters, strides=strides[i], padding='same', kernel_size=(filter_sizes[i]),\n",
    "                                 kernel_initializer='he_normal', activation='relu')(x))\n",
    "        \n",
    "        # pool_size calculation: (Width - (Filter_size * 2*Padding))/Stride\n",
    "        pool_size = int((maxlen-(filter_sizes[i]*2))/strides[i])\n",
    "        maxpool_layers.append(MaxPool1D(pool_size=pool_size, strides=strides[i])(conv_layers[i]))\n",
    "        \n",
    "    # Concatenate pooling layers outputs\n",
    "    if len(maxpool_layers)==1:\n",
    "        z = maxpool_layers[0]\n",
    "    else:\n",
    "        z = Concatenate(axis=1)(maxpool_layers)\n",
    "    \n",
    "    # Finish network with flattened layer, dropout, and fully connected layer\n",
    "    z = Flatten()(z)\n",
    "    z = Dropout(dropout)(z)\n",
    "    z = Dense(64, activation='relu')(z)\n",
    "    preds = Dense(1, activation='sigmoid')(z)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "    model.summary()\n",
    "    \n",
    "    plot_model(model, to_file='./ims/ConvNet1D.png', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true,
    "_uuid": "9aeb979e4a74bb9d6d269ea717b3beeddf2c2509"
   },
   "outputs": [],
   "source": [
    "threshold = 0.35 # Experimentally found to be the best threshold\n",
    "class F1Evaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            y_pred = (y_pred > threshold).astype(int)\n",
    "            score = f1_score(self.y_val, y_pred)\n",
    "            print(\"\\n F1 Score - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "            \n",
    "F1_Score = F1Evaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true,
    "_uuid": "738691c29ce46a05923efc18e3fada0c308e611e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            (None, 100)          0                                            \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, 100, 300)     15000000    input_2[0][0]                    \n__________________________________________________________________________________________________\nconv1d_7 (Conv1D)               (None, 100, 32)      9632        embedding_2[0][0]                \n__________________________________________________________________________________________________\nconv1d_8 (Conv1D)               (None, 34, 32)       9632        embedding_2[0][0]                \n__________________________________________________________________________________________________\nconv1d_9 (Conv1D)               (None, 100, 32)      28832       embedding_2[0][0]                \n__________________________________________________________________________________________________\nconv1d_10 (Conv1D)              (None, 34, 32)       28832       embedding_2[0][0]                \n__________________________________________________________________________________________________\nconv1d_11 (Conv1D)              (None, 100, 32)      48032       embedding_2[0][0]                \n__________________________________________________________________________________________________\nconv1d_12 (Conv1D)              (None, 34, 32)       48032       embedding_2[0][0]                \n__________________________________________________________________________________________________\nmax_pooling1d_7 (MaxPooling1D)  (None, 3, 32)        0           conv1d_7[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling1d_8 (MaxPooling1D)  (None, 1, 32)        0           conv1d_8[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling1d_9 (MaxPooling1D)  (None, 7, 32)        0           conv1d_9[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling1d_10 (MaxPooling1D) (None, 2, 32)        0           conv1d_10[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling1d_11 (MaxPooling1D) (None, 11, 32)       0           conv1d_11[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling1d_12 (MaxPooling1D) (None, 2, 32)        0           conv1d_12[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 26, 32)       0           max_pooling1d_7[0][0]            \n                                                                 max_pooling1d_8[0][0]            \n                                                                 max_pooling1d_9[0][0]            \n                                                                 max_pooling1d_10[0][0]           \n                                                                 max_pooling1d_11[0][0]           \n                                                                 max_pooling1d_12[0][0]           \n__________________________________________________________________________________________________\nflatten_2 (Flatten)             (None, 832)          0           concatenate_2[0][0]              \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 832)          0           flatten_2[0][0]                  \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 64)           53312       dropout_2[0][0]                  \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 1)            65          dense_3[0][0]                    \n==================================================================================================\nTotal params: 15,226,369\nTrainable params: 226,369\nNon-trainable params: 15,000,000\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A few parameters to define for the network. Feel free to experiment\n",
    "filter_sizes = [1,1,3,3,5,5]\n",
    "strides = [1,3,1,3,1,3]\n",
    "num_filters = 32\n",
    "dropout = 0.1\n",
    "embed_train = False\n",
    "\n",
    "epochs = 3\n",
    "batch_size = 512\n",
    "\n",
    "# Create and train network\n",
    "cnn = create_cnn(filter_sizes, strides, num_filters, embed_train=embed_train, dropout=dropout)\n",
    "history = cnn.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs,\n",
    "                  batch_size=batch_size, callbacks=[F1_Score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold\n",
    "Experimentally find best threshold to use for final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "06d3f429c185984a6361a343ec67f14a17da0f5d"
   },
   "outputs": [],
   "source": [
    "# The best results are seen with a threshold between 0.1 and 0.5\n",
    "thresholds = np.arange(0.1, 0.6, 0.1)\n",
    "\n",
    "best_thresh = None\n",
    "best_score = 0.\n",
    "\n",
    "# Make predictions and evaluate f1 score for each threshold value\n",
    "for thresh in thresholds:\n",
    "    y_pred = cnn.predict(X_val, verbose=0)\n",
    "    y_pred = (y_pred>thresh).astype(int)\n",
    "    score = f1_score(y_val, y_pred)\n",
    "    print('F1 Score for threshold {:0.1f}: {:0.3f}'.format(thresh, score))\n",
    "    \n",
    "    # Store best threshold for later use in predictions\n",
    "    if not best_thresh or score>best_score:\n",
    "        best_thresh = thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61aeb24e48c578594d26d0631a46aad49a215c4e"
   },
   "source": [
    "# 4. Predictions\nThe remainder of this notebok will generate predictions from the test set and write them to a submission csv file for the kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "91e9da1a1d551932c34405c3a7ed185632f12260"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')\n",
    "X_test = test_df['question_text'].values\n",
    "\n",
    "# Perform the same preprocessing as was done on the training set\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "# Make predictions, ensure that predictions are in integer form\n",
    "# Use best threshold from previous section\n",
    "preds = np.rint(cnn.predict([X_test], batch_size=1024, verbose=1))\n",
    "y_pred = (preds>best_thresh).astype(int)\n",
    "test_df['prediction'] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "72f90edd0b8a0eb4c644e917f7c02068378ad161"
   },
   "source": [
    "Let's examine a few examples of sincere predictions and insincere predictions. It appears that our network is making meaningful predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "5b7bd3f417dfa01973f20f12fe967ec61ff3dc69"
   },
   "outputs": [],
   "source": [
    "n=5\n",
    "sin_sample = test_df.loc[test_df['prediction'] == 0]['question_text'].head(n)\n",
    "print('Sincere Samples:')\n",
    "for idx, row in enumerate(sin_sample):\n",
    "    print('{}'.format(idx+1), row)\n",
    "\n",
    "print('\\n')\n",
    "print('Insincere Samples:')\n",
    "insin_sample = test_df.loc[test_df['prediction'] == 1]['question_text'].head(n)\n",
    "for idx, row in enumerate(insin_sample):\n",
    "    print('{}'.format(idx+1), row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "988fa1a03853289b65bb4c1845c5b7c333868cb8"
   },
   "outputs": [],
   "source": [
    "test_df = test_df.drop('question_text', axis=1)\n",
    "test_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}